# YOLOV11 - ULTRAANALYTIC ğŸš¦ğŸ“Š

Sistema de **detecciÃ³n, conteo y anÃ¡lisis vehicular/peatonal** basado en **YOLOv8/YOLOv11**, con interfaz **PySide6 (Qt)** y soporte para **videos de dron**.  
Permite definir **regiones de interÃ©s (ROI)**, realizar **conteo por categorÃ­as**, trazar **direcciones de flujo** y **exportar resultados profesionales a Excel**.

---

## âœ¨ CaracterÃ­sticas principales

- **Entrenamiento** personalizado desde videos (`train_module.py`).
- **DefiniciÃ³n de ROI** con editor visual, guardado en `roi.json` o `<video>.roi.json`.
- **DetecciÃ³n en tiempo real** de:
  - ğŸš— VehÃ­culo menor (`car`)
  - ğŸšŒ Buses urbanos (`bus`)
  - ğŸï¸ Motocicletas (`motorcycle`)
  - ğŸš¶â€â™‚ï¸ Peatones (`person`)
  - ğŸš™ VehÃ­culos estacionados (categorÃ­as derivadas)
- **Conteo Ãºnico por ID** â†’ evita duplicados y estacionados.
- **ExportaciÃ³n a Excel** con:
  - Bordes y estilos profesionales
  - Columnas autoajustables
  - Conteo por categorÃ­a, fecha e intersecciÃ³n
- **Direcciones de trÃ¡nsito** detectadas automÃ¡ticamente:
  - LÃ­nea curva por carril
  - Flecha al final del tramo con el color del carril
- **UI Dark Mode** con botones animados (*Fizzy CSS Button*).
- **Loaders animados** (*Particle Orbit*) como splash y durante procesos.
- Compatible con **CUDA (NVIDIA RTX)** para aceleraciÃ³n en GPU.

---

## ğŸ“‚ Estructura del proyecto

```
YOLOV11-ULTRAANALYTIC/
â”œâ”€â”€ main_app.py          # Interfaz principal de detecciÃ³n y conteo
â”œâ”€â”€ train_module.py      # Genera dataset desde videos y entrena modelos
â”œâ”€â”€ requirements.txt     # Dependencias del proyecto
â”œâ”€â”€ README.md            # DocumentaciÃ³n principal
â”œâ”€â”€ .gitignore
â”œâ”€â”€ weights/             # Modelos entrenados (best.pt, last.pt)
â”œâ”€â”€ datasets/            # Carpeta para datasets (no versionada en Git)
â”‚   â”œâ”€â”€ images/train/
â”‚   â”œâ”€â”€ images/val/
â”‚   â”œâ”€â”€ labels/train/
â”‚   â””â”€â”€ labels/val/
â”œâ”€â”€ runs/                # Resultados de entrenamiento (ignorada en git)
â””â”€â”€ roi.json             # ROI por defecto (opcional)
```

---

## ğŸ§  Modelos de aprendizaje

### Clases detectadas
El sistema estÃ¡ entrenado para reconocer las siguientes clases:

- `car` â†’ VehÃ­culos menores
- `bus` â†’ Buses urbanos
- `motorcycle` â†’ Motocicletas
- `person` â†’ Peatones
- `car_parked`, `bus_parked`, `motorcycle_parked` â†’ Detectados como estacionados (via tracker temporal)

### Entrenamiento (`train_module.py`)
- Entrada: video `.mp4` (ej. desde dron).
- Salida: dataset YOLO (`images/`, `labels/`) + `dataset.yaml`.
- Modelo base: `yolov8n.pt` o `yolov8s.pt`.
- ParametrizaciÃ³n:
  - Ã‰pocas: 20â€“50
  - TamaÃ±o de imagen: 640
  - Batch ajustable segÃºn GPU
- Guardado automÃ¡tico en `runs/detect/train.../weights/`.

Ejemplo:
```bash
python train_module.py --video videos/interseccion.mp4 --out datasets/interseccion   --epochs 30 --imgsz 640
```

El mejor modelo se guarda como `best.pt` y se carga por defecto en la aplicaciÃ³n.

---

## ğŸ–¥ï¸ Uso de la aplicaciÃ³n (`main_app.py`)

### 1) Cargar video
```bash
python main_app.py
```
- Selecciona el video `.mp4`.
- Se abrirÃ¡ el **editor ROI** â†’ dibuja el polÃ­gono de intersecciÃ³n â†’ presiona `S` para guardar.
- Pregunta: â€œÂ¿Deseas guardar este ROI?â€ â†’ **Aceptar**.

### 2) SelecciÃ³n del modelo
- AutomÃ¡ticamente busca `runs/.../best.pt`.
- TambiÃ©n puedes cargar manualmente otro `.pt`.

### 3) Iniciar anÃ¡lisis
- BotÃ³n **Iniciar** â†’ cambia a **â€œAnalizando datosâ€¦â€**.
- Durante el proceso verÃ¡s:
  - Progreso por frame (y tiempo estimado).
  - Etiquetas de detecciÃ³n mÃ¡s pequeÃ±as (menos intrusivas).
  - Trazos de flujo + flechas curvas en cada calle.
- Al terminar: botÃ³n â†’ **â€œTerminadoâ€**.

### 4) Exportar resultados
- BotÃ³n **Exportar Excel** â†’ crea un archivo con:
  - Fecha de anÃ¡lisis
  - Nombre de intersecciÃ³n
  - Conteo por categorÃ­a
  - Formato con bordes y autoajuste de columnas

---

## âš™ï¸ Requisitos

- Python 3.10 â€“ 3.13
- GPU NVIDIA (CUDA 12.x recomendado)
- Dependencias:
  ```bash
  pip install -r requirements.txt
  # si tienes CUDA 12.4:
  pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio
  ```

---

## ğŸ“ Ejemplo de `roi.json`

```json
{
  "normalized": true,
  "invert": false,
  "polygons": [
    [[0.10, 0.35], [0.90, 0.35], [0.90, 0.65], [0.10, 0.65]]
  ]
}
```

- Coordenadas normalizadas (0â€“1).
- Puede contener varios polÃ­gonos en `"polygons"`.

---

## ğŸ“Š Ejemplo de salida Excel

| CategorÃ­a         | Conteo |
|-------------------|--------|
| VehÃ­culos menores | 154    |
| Buses urbanos     | 12     |
| Motocicletas      | 38     |
| Peatones          | 89     |
| Estacionados      | 21     |

---

## ğŸ”® Futuras mejoras

- Refinar detecciÃ³n de peatones en escenas con alta altura de dron.  
- IntegraciÃ³n con mapas GIS para geo-referenciar intersecciones.  
- Dashboards en tiempo real (streamlit/plotly).  
- Entrenamiento incremental con nuevos videos.  

---

## ğŸ“œ Licencia
Este proyecto estÃ¡ bajo la licencia MIT, ver archivo [LICENSE](LICENSE).
